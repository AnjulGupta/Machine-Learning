{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "from numpy import linalg as la\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>193</td>\n",
       "      <td>441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>167</td>\n",
       "      <td>9724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  service  src_bytes  dst_bytes  hot  num_failed_logins  \\\n",
       "0         0       25        193        441    0                  0   \n",
       "1         0       38          0          0    0                  0   \n",
       "2         0       25        167       9724    0                  0   \n",
       "3         0       20       1339          0    0                  0   \n",
       "4         0       37          0          0    0                  0   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "0                0         0                   0                 0  ...   \n",
       "1                0         0                   0                 0  ...   \n",
       "2                0         0                   0                 0  ...   \n",
       "3                0         0                   0                 0  ...   \n",
       "4                0         0                   0                 0  ...   \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                 255                    1.00                    0.00   \n",
       "1                   1                    0.00                    0.07   \n",
       "2                 255                    1.00                    0.00   \n",
       "3                  31                    0.23                    0.04   \n",
       "4                  25                    0.10                    0.05   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.07                         0.04   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.03                         0.06   \n",
       "3                         0.23                         0.00   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.04                   0.0   \n",
       "1                  0.00                      0.00                   1.0   \n",
       "2                  0.00                      0.00                   0.0   \n",
       "3                  0.02                      0.00                   0.0   \n",
       "4                  1.00                      1.00                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                       0.0   normal  \n",
       "1                       1.0      dos  \n",
       "2                       0.0   normal  \n",
       "3                       0.0   normal  \n",
       "4                       0.0      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df[0:2000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24998, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df_label=df.iloc[:,-1]\n",
    "df.drop(df.columns[[-1,]], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df['dst'])\n",
    "# df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dos' 'normal' 'probe' 'r2l' 'u2r']\n",
      "[ 9114 13364  2313   197    10]\n"
     ]
    }
   ],
   "source": [
    "x,y= np.unique(df_label,return_counts =True)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration                         310.648452\n",
      "service                           32.024842\n",
      "src_bytes                      24424.087767\n",
      "dst_bytes                       3305.596648\n",
      "hot                                0.193535\n",
      "num_failed_logins                  0.001200\n",
      "num_compromised                    0.229418\n",
      "num_root                           0.251700\n",
      "num_file_creations                 0.014841\n",
      "num_access_files                   0.004360\n",
      "count                             84.466757\n",
      "srv_count                         27.767061\n",
      "serror_rate                        0.284812\n",
      "srv_serror_rate                    0.282262\n",
      "rerror_rate                        0.119152\n",
      "srv_rerror_rate                    0.120744\n",
      "same_srv_rate                      0.661691\n",
      "diff_srv_rate                      0.062590\n",
      "srv_diff_host_rate                 0.096546\n",
      "dst_host_count                   182.405832\n",
      "dst_host_srv_count               115.254580\n",
      "dst_host_same_srv_rate             0.520648\n",
      "dst_host_diff_srv_rate             0.083117\n",
      "dst_host_same_src_port_rate        0.148392\n",
      "dst_host_srv_diff_host_rate        0.032109\n",
      "dst_host_serror_rate               0.284272\n",
      "dst_host_srv_serror_rate           0.278418\n",
      "dst_host_rerror_rate               0.118272\n",
      "dst_host_srv_rerror_rate           0.119189\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.690213</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.447897</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488729</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "\n",
       "   dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0       -1.690213            1.262872                1.067572   \n",
       "1        0.732947           -1.032512               -1.159545   \n",
       "2       -1.447897            1.262872                1.067572   \n",
       "3       -0.488729           -0.761404               -0.647308   \n",
       "4        0.732947           -0.815626               -0.936833   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0               -0.441083                    -0.253425   \n",
       "1               -0.069609                    -0.479722   \n",
       "2               -0.441083                    -0.382738   \n",
       "3               -0.228812                     0.263823   \n",
       "4               -0.175745                    -0.479722   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                     0.071030             -0.639500   \n",
       "1                    -0.289006             -0.639500   \n",
       "2                     0.251048             -0.639500   \n",
       "3                    -0.289006             -0.594507   \n",
       "4                    -0.289006              1.610108   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \n",
       "0                 -0.535332             -0.386077                 -0.374982  \n",
       "1                 -0.625146              2.878240                  2.771138  \n",
       "2                 -0.625146             -0.386077                 -0.374982  \n",
       "3                 -0.625146             -0.386077                 -0.374982  \n",
       "4                  1.620205             -0.386077                 -0.374982  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=np.mean(df)\n",
    "print(mean)\n",
    "std_dev=np.std(df)\n",
    "df=(df-np.mean(df,axis=0))/np.std(df,axis=0)\n",
    "# df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to put Weight and Bias between Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wgt_n_Bias:\n",
    "    def __init__(self, current_layer_nodes,next_layer_nodes, activation_function):\n",
    "        #nodes in current layer\n",
    "        self.current_layer_nodes = current_layer_nodes\n",
    "        #nodes in next layer\n",
    "        self.next_layer_nodes = next_layer_nodes\n",
    "        #activation_function \n",
    "        self.activation_function = activation_function\n",
    "        #activations\n",
    "        self.activations = np.zeros([current_layer_nodes,1])\n",
    "        \n",
    "        # putting weights and bias for layers\n",
    "        \n",
    "        # if not output layer set random weights and bias\n",
    "        if next_layer_nodes != 0:\n",
    "            self.weights = np.random.normal(0, 0.001, size=(current_layer_nodes, next_layer_nodes))\n",
    "            self.bias = np.random.normal(0, 0.001, size=(1, next_layer_nodes))\n",
    "        # if output layer set weight and bias to None\n",
    "        else:\n",
    "            self.weights = None\n",
    "            self.bias = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):  \n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):  \n",
    "    return sigmoid(x) *(1-sigmoid (x))\n",
    "\n",
    "def softmax(A):  \n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    x[x < 0] = 0\n",
    "    return x\n",
    "\n",
    "def tanh_der(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "def relu_der(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def derlinear(x):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to  make Neural Nertwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neu_net:\n",
    "    def __init__(self, layers, node_list, activation_function):\n",
    "        self.layers = layers\n",
    "        self.node_list = node_list\n",
    "        self.layer_list = []\n",
    "        self.error = 0\n",
    "        self.learning_rate = 0.000001\n",
    "        self.cost_function = \"mean_squared\"\n",
    "\n",
    "        for i in range(layers):\n",
    "            \n",
    "            if i != layers-1:\n",
    "                layer_i = Wgt_n_Bias(node_list[i], node_list[i+1], activation_function[i])\n",
    "            else:\n",
    "                #if i is output layer\n",
    "                layer_i = Wgt_n_Bias(node_list[i], 0, activation_function[i])\n",
    "            self.layer_list.append(layer_i)\n",
    "                   \n",
    "\n",
    "    def forward_propagation(self, inputs):\n",
    "        self.layer_list[0].activations = inputs\n",
    "        for i in range(self.layers-1):\n",
    "            \n",
    "            temp = np.add(np.matmul(self.layer_list[i].activations, self.layer_list[i].weights), self.layer_list[i].bias)\n",
    "\n",
    "            if self.layer_list[i+1].activation_function == \"sigmoid\":\n",
    "                self.layer_list[i+1].activations = sigmoid(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"softmax\":\n",
    "                self.layer_list[i+1].activations = softmax(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"relu\":\n",
    "                self.layer_list[i+1].activations = relu(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"tanh\":\n",
    "                self.layer_list[i+1].activations = tanh(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"linear\":\n",
    "                self.layer_list[i+1].activations = linear(temp)\n",
    "            else:\n",
    "                self.layer_list[i+1].activations = temp\n",
    "    \n",
    "    #Error func - mean-squared\n",
    "    def Error_func(self,label_vector):\n",
    "            #self.error = np.sum(-label_vector * np.log(self.layer_list[-1].activations))\n",
    "        self.error = np.mean(np.divide(np.square(np.subtract(label_vector, self.layer_list[self.layers-1].activations)), 2))\n",
    "    \n",
    "    def back_propagation(self,label_vector):\n",
    "        \n",
    "        #for the weight and bias of output layer\n",
    "        i = self.layers-1\n",
    "        diff_a_z=0\n",
    "        \n",
    "        #\n",
    "        if self.layer_list[i].activation_function == \"sigmoid\":\n",
    "            diff_e_z=self.layer_list[i].activations*(1-self.layer_list[i].activations)*(self.layer_list[i].activations-label_vector)\n",
    "        else:\n",
    "            diff_e_z=self.layer_list[i].activations-label_vector\n",
    "        #diff_e_z=self.layer_list[i].activations-label_vector\n",
    "        diff_z_w=self.layer_list[i-1].activations\n",
    "        diff_e_w=np.dot(diff_z_w.T, diff_e_z) \n",
    "        diff_e_b=diff_e_z\n",
    "\n",
    "        self.layer_list[i-1].weights -= self.learning_rate * diff_e_w\n",
    "        self.layer_list[i-1].bias -= self.learning_rate * diff_e_b.sum(axis=0)\n",
    "       \n",
    "        for i in range(i-1,0,-1):\n",
    "            diff_z_a=self.layer_list[i].weights\n",
    "            diff_e_a=np.dot(diff_e_z,diff_z_a.T)\n",
    "            \n",
    "            temp = np.add(np.matmul(self.layer_list[i-1].activations, self.layer_list[i-1].weights), self.layer_list[i-1].bias)\n",
    "\n",
    "            if self.layer_list[i].activation_function == \"sigmoid\":\n",
    "                diff_a_z=sigmoid_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"relu\":\n",
    "                diff_a_z=relu_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"tanh\":\n",
    "                diff_a_z=tanh_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"linear\":\n",
    "                diff_a_z=derlinear(temp)\n",
    "\n",
    "            diff_z_w=self.layer_list[i-1].activations\n",
    "            diff_e_w=np.dot(diff_z_w.T,(diff_a_z*diff_e_a))\n",
    "            diff_e_b = diff_e_a*diff_a_z\n",
    "            diff_e_z=diff_e_b\n",
    "    \n",
    "            self.layer_list[i-1].weights -= self.learning_rate * diff_e_w\n",
    "            self.layer_list[i-1].bias -= self.learning_rate * diff_e_b.sum(axis=0)\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Network(inputs, num_epochs):\n",
    "    nn.error = 0\n",
    "    for j in range(num_epochs): \n",
    "        nn.forward_propagation(inputs)\n",
    "        nn.Error_func(inputs)\n",
    "        print(\"Iter \"+str(j)+\" : \"+str(nn.error))\n",
    "        nn.back_propagation(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn=Neu_net(layers=3, [l1,l2,l3], [None,\"f2\",\"f3\"])\n",
    "# nn=Neu_net(3, [29,14,29], [None,\"sigmoid\",\"sigmoid\"])\n",
    "nn=Neu_net(3, [29,14,29], [None,\"linear\",\"linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 : 0.5000003357871354\n",
      "Iter 1 : 0.49999838485246345\n",
      "Iter 2 : 0.4999963504895961\n",
      "Iter 3 : 0.49999408753799235\n",
      "Iter 4 : 0.4999914290166172\n",
      "Iter 5 : 0.4999881694286703\n",
      "Iter 6 : 0.4999840440037172\n",
      "Iter 7 : 0.4999787016495276\n",
      "Iter 8 : 0.4999716686985898\n",
      "Iter 9 : 0.4999622995274478\n",
      "Iter 10 : 0.49994970869160527\n",
      "Iter 11 : 0.4999326772008711\n",
      "Iter 12 : 0.49990952274724704\n",
      "Iter 13 : 0.49987791980098906\n",
      "Iter 14 : 0.4998346501256824\n",
      "Iter 15 : 0.4997752569308259\n",
      "Iter 16 : 0.4996935659587808\n",
      "Iter 17 : 0.49958102357110545\n",
      "Iter 18 : 0.4994257846359345\n",
      "Iter 19 : 0.49921146126389004\n",
      "Iter 20 : 0.4989154175957075\n",
      "Iter 21 : 0.49850646842322455\n",
      "Iter 22 : 0.49794181752514494\n",
      "Iter 23 : 0.4971630715307024\n",
      "Iter 24 : 0.49609122053634147\n",
      "Iter 25 : 0.49462065160710317\n",
      "Iter 26 : 0.49261266778413\n",
      "Iter 27 : 0.4898897988077243\n",
      "Iter 28 : 0.4862336358133059\n",
      "Iter 29 : 0.48139116304787033\n",
      "Iter 30 : 0.47509734083966576\n",
      "Iter 31 : 0.4671235736073642\n",
      "Iter 32 : 0.4573589445809742\n",
      "Iter 33 : 0.44591750267169017\n",
      "Iter 34 : 0.4332359621102221\n",
      "Iter 35 : 0.42009157178802803\n",
      "Iter 36 : 0.40746656191741026\n",
      "Iter 37 : 0.39625919581178065\n",
      "Iter 38 : 0.3869730171456656\n",
      "Iter 39 : 0.37957769634908656\n",
      "Iter 40 : 0.37362131616595057\n",
      "Iter 41 : 0.368484717187715\n",
      "Iter 42 : 0.36360477425016496\n",
      "Iter 43 : 0.35858316857246686\n",
      "Iter 44 : 0.3532023324628004\n",
      "Iter 45 : 0.3474021737476491\n",
      "Iter 46 : 0.34125099872265535\n",
      "Iter 47 : 0.33491786568602533\n",
      "Iter 48 : 0.32864094405727895\n",
      "Iter 49 : 0.3226866975776784\n",
      "Iter 50 : 0.31730198231368134\n",
      "Iter 51 : 0.31266919597922826\n",
      "Iter 52 : 0.3088776784999436\n",
      "Iter 53 : 0.30591982076500324\n",
      "Iter 54 : 0.30371036399312684\n",
      "Iter 55 : 0.3021186224149926\n",
      "Iter 56 : 0.3010009270375823\n",
      "Iter 57 : 0.30022441990733745\n",
      "Iter 58 : 0.29967949270961153\n",
      "Iter 59 : 0.29928281510389165\n",
      "Iter 60 : 0.2989746759067808\n",
      "Iter 61 : 0.29871399180848607\n",
      "Iter 62 : 0.29847313257839114\n",
      "Iter 63 : 0.29823357196959044\n",
      "Iter 64 : 0.2979826298680697\n",
      "Iter 65 : 0.29771120449577404\n",
      "Iter 66 : 0.2974122710895214\n",
      "Iter 67 : 0.29707992338058625\n",
      "Iter 68 : 0.2967087791241341\n",
      "Iter 69 : 0.29629362235700335\n",
      "Iter 70 : 0.2958291981868709\n",
      "Iter 71 : 0.29531010757954845\n",
      "Iter 72 : 0.29473077121602825\n",
      "Iter 73 : 0.2940854455665395\n",
      "Iter 74 : 0.29336828317283337\n",
      "Iter 75 : 0.2925734344301141\n",
      "Iter 76 : 0.2916951910070986\n",
      "Iter 77 : 0.2907281720597356\n",
      "Iter 78 : 0.2896675538786258\n",
      "Iter 79 : 0.288509341660016\n",
      "Iter 80 : 0.28725067871479887\n",
      "Iter 81 : 0.28589018365696567\n",
      "Iter 82 : 0.28442830009685804\n",
      "Iter 83 : 0.28286763649607144\n",
      "Iter 84 : 0.28121326684271036\n",
      "Iter 85 : 0.2794729567870047\n",
      "Iter 86 : 0.27765727630499126\n",
      "Iter 87 : 0.27577956050150904\n",
      "Iter 88 : 0.2738556863841416\n",
      "Iter 89 : 0.27190364633443076\n",
      "Iter 90 : 0.26994291848458485\n",
      "Iter 91 : 0.2679936586713928\n",
      "Iter 92 : 0.2660757648165788\n",
      "Iter 93 : 0.2642078878776133\n",
      "Iter 94 : 0.2624064788754036\n",
      "Iter 95 : 0.26068496471581487\n",
      "Iter 96 : 0.2590531345213674\n",
      "Iter 97 : 0.25751679397332916\n",
      "Iter 98 : 0.2560777118319199\n",
      "Iter 99 : 0.2547338466314798\n"
     ]
    }
   ],
   "source": [
    "Training_Network(df.values,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight & Bias: Saving and Retrieving by file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nn.layers):\n",
    "    np.save('wgts'+str(i)+'.npy',nn.layer_list[i].weights)\n",
    "    np.save('bias'+str(i)+'.npy',nn.layer_list[i].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nn.layers):\n",
    "    nn.layer_list[i].weights = np.load('wgts'+str(i)+'.npy')\n",
    "    nn.layer_list[i].bias=np.load('bias'+str(i)+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data-Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.forward_propagation(validate.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=nn.layer_list[1].activations\n",
    "dimensions=ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24998, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39512923,  1.16004135, -0.60427105, ..., -0.16732301,\n",
       "         1.38866567,  1.03616317],\n",
       "       [-1.81619823, -0.21007847,  2.42887414, ...,  2.84115726,\n",
       "        -1.97323641, -0.35032134],\n",
       "       [ 0.38543158,  1.14042068, -0.58435004, ..., -0.14214107,\n",
       "         1.34695763,  1.01524568],\n",
       "       ...,\n",
       "       [ 0.12789625, -2.06433218, -0.89458542, ...,  2.57123346,\n",
       "         3.82604317, -2.68274968],\n",
       "       [ 0.70773146,  2.04995021, -0.87432709, ..., -0.02561592,\n",
       "         1.45517332,  0.8442292 ],\n",
       "       [ 0.12541553, -2.02297696, -0.11699317, ..., -1.10967848,\n",
       "        -1.6086993 , -1.60670342]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(k,dimensions) :\n",
    "    rows = dimensions.shape[0]\n",
    "    cols = dimensions.shape[1]\n",
    "    \n",
    "    mn = np.mean(dimensions, axis = 0)\n",
    "    print(mn)\n",
    "    std = np.std(dimensions, axis = 0)\n",
    "    centers = np.random.randn(k,cols)*std + mn\n",
    "    \n",
    "#     plt.scatter(centers[:,0], centers[:,1], marker='+', c='r', s=150)\n",
    "    \n",
    "    # to store old centers\n",
    "    co = np.zeros(centers.shape)\n",
    "    # to Store new centers\n",
    "    cn = deepcopy(centers) \n",
    "\n",
    "    clusters = np.zeros(rows)\n",
    "    distances = np.zeros((rows,k))\n",
    "\n",
    "    error = np.linalg.norm(cn - co)\n",
    "\n",
    "    # When, after an update, the estimate of that center stays the same, exit loop\n",
    "    while error != 0:\n",
    "        # Measure the distance to every center\n",
    "        for i in range(k):\n",
    "            distances[:,i] = np.linalg.norm(dimensions - cn[i], axis=1)\n",
    "        # Assign all training data to closest center\n",
    "        clusters = np.argmin(distances, axis = 1)\n",
    "\n",
    "        co = deepcopy(cn)\n",
    "        # Calculate mean for every cluster and update the center\n",
    "        for i in range(k):\n",
    "            cn[i] = np.mean(dimensions[clusters == i], axis=0)\n",
    "        error = np.linalg.norm(cn - co)\n",
    "    # centers_new   \n",
    "#     plt.scatter(cn[:,0], cn[:,1], marker='+', c='g', s=150)\n",
    "#     print(clusters)\n",
    "#     print(np.unique(clusters))\n",
    "    \n",
    "    #\n",
    "    cmat=contingency_matrix(clusters,lclass)\n",
    "#     print(cmat)\n",
    "\n",
    "    for i,item in enumerate(cmat):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "    \n",
    "    pure=0\n",
    "    for row in cmat:\n",
    "#         print(max(row))\n",
    "        pure+=max(row)\n",
    "    purity0=pure/len(df_label)\n",
    "    \n",
    "    return purity0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_fun(dimensions) :\n",
    "    \n",
    "    GMM=GaussianMixture(n_components=5).fit(dimensions)\n",
    "    gmmlabel=GMM.predict(dimensions)\n",
    "    \n",
    "    np.unique(gmmlabel)\n",
    "    cmat=contingency_matrix(gmmlabel,lclass)\n",
    "\n",
    "    for i,item in enumerate(cmat):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "\n",
    "    pure1=0\n",
    "    for i in cmat:\n",
    "        pure1+=max(i)\n",
    "    #     print(max(i))\n",
    "    purity1=pure1/len(df_label)\n",
    "    print('GMM Purity:', purity1)\n",
    "    \n",
    "    return purity1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierrarchial fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchial_cluster(dimensions) :\n",
    "    cc=AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='single')\n",
    "    aclabel=cc.fit_predict(dimensions)\n",
    "    np.unique(aclabel)\n",
    "    \n",
    "    cmat2=contingency_matrix(aclabel,lclass)\n",
    "    \n",
    "    for i,item in enumerate(cmat2):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "\n",
    "    pure2=0\n",
    "    for i in cmat2:\n",
    "        pure2+=max(i)\n",
    "    purity2=pure2/len(df_label)\n",
    "    print('Hierarchical Purity:', purity2)\n",
    "    \n",
    "    return purity2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting unique vals of label [xAttack] attr into integer categories\n",
    "uv = np.unique(df_label)\n",
    "# print(uv)\n",
    "cat = [0,1,2,3,4]\n",
    "#converted label data into int class list \n",
    "lclass=[]\n",
    "for i in range(len(df_label)):\n",
    "    if df_label[i]=='dos':\n",
    "        lclass.append(cat[0])\n",
    "    if df_label[i]=='normal':\n",
    "        lclass.append(cat[1])\n",
    "    if df_label[i]=='probe':\n",
    "        lclass.append(cat[2])\n",
    "    if df_label[i]=='r2l':\n",
    "        lclass.append(cat[3])\n",
    "    if df_label[i]=='u2r':\n",
    "        lclass.append(cat[4])\n",
    "# print(lclass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kmeans on reduced dimenasions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00220627  0.00056387  0.00039642 -0.00167644 -0.00032273 -0.00087671\n",
      "  0.00126121 -0.0018531   0.00105958 -0.00013476  0.00014029  0.00076272\n",
      " -0.00027348  0.00145493]\n",
      "Purity of clusters : 0  : 46.74434544208362\n",
      "Purity of clusters : 1  : 72.95110798452339\n",
      "Purity of clusters : 2  : 87.23989960327098\n",
      "Purity of clusters : 3  : 98.77871474265775\n",
      "Purity of clusters : 4  : 100.0\n",
      "K-means Purity is: 0.8406672533802704\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "purity0 = k_means(k,dimensions)\n",
    "print('K-means Purity is:', purity0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GMM_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of clusters : 0  : 64.32893289328933\n",
      "Purity of clusters : 1  : 46.60061496412709\n",
      "Purity of clusters : 2  : 100.0\n",
      "Purity of clusters : 3  : 100.0\n",
      "Purity of clusters : 4  : 86.48180242634315\n",
      "GMM Purity: 0.8200656052484199\n"
     ]
    }
   ],
   "source": [
    "purity1 = GMM_fun(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hierarchial clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of clusters : 0  : 100.0\n",
      "Purity of clusters : 1  : 100.0\n",
      "Purity of clusters : 2  : 53.445378151260506\n",
      "Purity of clusters : 3  : 100.0\n",
      "Purity of clusters : 4  : 100.0\n",
      "Hierarchical Purity: 0.5346027682214577\n"
     ]
    }
   ],
   "source": [
    "purity2 = hierarchial_cluster(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIE Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "slices_hours = [purity0, purity1, purity2]\n",
    "activities = ['K-Means', 'GMM', 'Hierarchical']\n",
    "explode = (0.025, 0.025, 0.025)\n",
    "colors = ['red', 'blue','green']\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(slices_hours, explode=explode,colors=colors, labels=activities, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=120)\n",
    "ax1.axis('equal') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
