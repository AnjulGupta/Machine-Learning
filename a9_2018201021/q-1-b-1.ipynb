{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "from numpy import linalg as la\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>193</td>\n",
       "      <td>441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>167</td>\n",
       "      <td>9724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  service  src_bytes  dst_bytes  hot  num_failed_logins  \\\n",
       "0         0       25        193        441    0                  0   \n",
       "1         0       38          0          0    0                  0   \n",
       "2         0       25        167       9724    0                  0   \n",
       "3         0       20       1339          0    0                  0   \n",
       "4         0       37          0          0    0                  0   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "0                0         0                   0                 0  ...   \n",
       "1                0         0                   0                 0  ...   \n",
       "2                0         0                   0                 0  ...   \n",
       "3                0         0                   0                 0  ...   \n",
       "4                0         0                   0                 0  ...   \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                 255                    1.00                    0.00   \n",
       "1                   1                    0.00                    0.07   \n",
       "2                 255                    1.00                    0.00   \n",
       "3                  31                    0.23                    0.04   \n",
       "4                  25                    0.10                    0.05   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.07                         0.04   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.03                         0.06   \n",
       "3                         0.23                         0.00   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.04                   0.0   \n",
       "1                  0.00                      0.00                   1.0   \n",
       "2                  0.00                      0.00                   0.0   \n",
       "3                  0.02                      0.00                   0.0   \n",
       "4                  1.00                      1.00                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                       0.0   normal  \n",
       "1                       1.0      dos  \n",
       "2                       0.0   normal  \n",
       "3                       0.0   normal  \n",
       "4                       0.0      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df[0:2000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24998, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df_label=df.iloc[:,-1]\n",
    "df.drop(df.columns[[-1,]], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df['dst'])\n",
    "# df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dos' 'normal' 'probe' 'r2l' 'u2r']\n",
      "[ 9114 13364  2313   197    10]\n"
     ]
    }
   ],
   "source": [
    "x,y= np.unique(df_label,return_counts =True)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration                         310.648452\n",
      "service                           32.024842\n",
      "src_bytes                      24424.087767\n",
      "dst_bytes                       3305.596648\n",
      "hot                                0.193535\n",
      "num_failed_logins                  0.001200\n",
      "num_compromised                    0.229418\n",
      "num_root                           0.251700\n",
      "num_file_creations                 0.014841\n",
      "num_access_files                   0.004360\n",
      "count                             84.466757\n",
      "srv_count                         27.767061\n",
      "serror_rate                        0.284812\n",
      "srv_serror_rate                    0.282262\n",
      "rerror_rate                        0.119152\n",
      "srv_rerror_rate                    0.120744\n",
      "same_srv_rate                      0.661691\n",
      "diff_srv_rate                      0.062590\n",
      "srv_diff_host_rate                 0.096546\n",
      "dst_host_count                   182.405832\n",
      "dst_host_srv_count               115.254580\n",
      "dst_host_same_srv_rate             0.520648\n",
      "dst_host_diff_srv_rate             0.083117\n",
      "dst_host_same_src_port_rate        0.148392\n",
      "dst_host_srv_diff_host_rate        0.032109\n",
      "dst_host_serror_rate               0.284272\n",
      "dst_host_srv_serror_rate           0.278418\n",
      "dst_host_rerror_rate               0.118272\n",
      "dst_host_srv_rerror_rate           0.119189\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.690213</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.447897</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488729</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "\n",
       "   dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0       -1.690213            1.262872                1.067572   \n",
       "1        0.732947           -1.032512               -1.159545   \n",
       "2       -1.447897            1.262872                1.067572   \n",
       "3       -0.488729           -0.761404               -0.647308   \n",
       "4        0.732947           -0.815626               -0.936833   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0               -0.441083                    -0.253425   \n",
       "1               -0.069609                    -0.479722   \n",
       "2               -0.441083                    -0.382738   \n",
       "3               -0.228812                     0.263823   \n",
       "4               -0.175745                    -0.479722   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                     0.071030             -0.639500   \n",
       "1                    -0.289006             -0.639500   \n",
       "2                     0.251048             -0.639500   \n",
       "3                    -0.289006             -0.594507   \n",
       "4                    -0.289006              1.610108   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \n",
       "0                 -0.535332             -0.386077                 -0.374982  \n",
       "1                 -0.625146              2.878240                  2.771138  \n",
       "2                 -0.625146             -0.386077                 -0.374982  \n",
       "3                 -0.625146             -0.386077                 -0.374982  \n",
       "4                  1.620205             -0.386077                 -0.374982  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=np.mean(df)\n",
    "print(mean)\n",
    "std_dev=np.std(df)\n",
    "df=(df-np.mean(df,axis=0))/np.std(df,axis=0)\n",
    "# df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to put Weight and Bias between Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wgt_n_Bias:\n",
    "    def __init__(self, current_layer_nodes,next_layer_nodes, activation_function):\n",
    "        #nodes in current layer\n",
    "        self.current_layer_nodes = current_layer_nodes\n",
    "        #nodes in next layer\n",
    "        self.next_layer_nodes = next_layer_nodes\n",
    "        #activation_function \n",
    "        self.activation_function = activation_function\n",
    "        #activations\n",
    "        self.activations = np.zeros([current_layer_nodes,1])\n",
    "        \n",
    "        # putting weights and bias for layers\n",
    "        \n",
    "        # if not output layer set random weights and bias\n",
    "        if next_layer_nodes != 0:\n",
    "            self.weights = np.random.normal(0, 0.001, size=(current_layer_nodes, next_layer_nodes))\n",
    "            self.bias = np.random.normal(0, 0.001, size=(1, next_layer_nodes))\n",
    "        # if output layer set weight and bias to None\n",
    "        else:\n",
    "            self.weights = None\n",
    "            self.bias = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):  \n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):  \n",
    "    return sigmoid(x) *(1-sigmoid (x))\n",
    "\n",
    "def softmax(A):  \n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    x[x < 0] = 0\n",
    "    return x\n",
    "\n",
    "def tanh_der(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "def relu_der(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def derlinear(x):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to  make Neural Nertwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neu_net:\n",
    "    def __init__(self, layers, node_list, activation_function):\n",
    "        self.layers = layers\n",
    "        self.node_list = node_list\n",
    "        self.layer_list = []\n",
    "        self.error = 0\n",
    "        self.learning_rate = 0.00001\n",
    "        self.cost_function = \"mean_squared\"\n",
    "\n",
    "        for i in range(layers):\n",
    "            \n",
    "            if i != layers-1:\n",
    "                layer_i = Wgt_n_Bias(node_list[i], node_list[i+1], activation_function[i])\n",
    "            else:\n",
    "                #if i is output layer\n",
    "                layer_i = Wgt_n_Bias(node_list[i], 0, activation_function[i])\n",
    "            self.layer_list.append(layer_i)\n",
    "                   \n",
    "\n",
    "    def forward_propagation(self, inputs):\n",
    "        self.layer_list[0].activations = inputs\n",
    "        for i in range(self.layers-1):\n",
    "            \n",
    "            temp = np.add(np.matmul(self.layer_list[i].activations, self.layer_list[i].weights), self.layer_list[i].bias)\n",
    "\n",
    "            if self.layer_list[i+1].activation_function == \"sigmoid\":\n",
    "                self.layer_list[i+1].activations = sigmoid(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"softmax\":\n",
    "                self.layer_list[i+1].activations = softmax(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"relu\":\n",
    "                self.layer_list[i+1].activations = relu(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"tanh\":\n",
    "                self.layer_list[i+1].activations = tanh(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"linear\":\n",
    "                self.layer_list[i+1].activations = linear(temp)\n",
    "            else:\n",
    "                self.layer_list[i+1].activations = temp\n",
    "    \n",
    "    #Error func - mean-squared\n",
    "    def Error_func(self,label_vector):\n",
    "            #self.error = np.sum(-label_vector * np.log(self.layer_list[-1].activations))\n",
    "        self.error = np.mean(np.divide(np.square(np.subtract(label_vector, self.layer_list[self.layers-1].activations)), 2))\n",
    "    \n",
    "    def back_propagation(self,label_vector):\n",
    "        \n",
    "        #for the weight and bias of output layer\n",
    "        i = self.layers-1\n",
    "        diff_a_z=0\n",
    "        \n",
    "        #\n",
    "        if self.layer_list[i].activation_function == \"sigmoid\":\n",
    "            diff_e_z=self.layer_list[i].activations*(1-self.layer_list[i].activations)*(self.layer_list[i].activations-label_vector)\n",
    "        else:\n",
    "            diff_e_z=self.layer_list[i].activations-label_vector\n",
    "        #diff_e_z=self.layer_list[i].activations-label_vector\n",
    "        diff_z_w=self.layer_list[i-1].activations\n",
    "        diff_e_w=np.dot(diff_z_w.T, diff_e_z) \n",
    "        diff_e_b=diff_e_z\n",
    "\n",
    "        self.layer_list[i-1].weights -= self.learning_rate * diff_e_w\n",
    "        self.layer_list[i-1].bias -= self.learning_rate * diff_e_b.sum(axis=0)\n",
    "       \n",
    "        for i in range(i-1,0,-1):\n",
    "            diff_z_a=self.layer_list[i].weights\n",
    "            diff_e_a=np.dot(diff_e_z,diff_z_a.T)\n",
    "            \n",
    "            temp = np.add(np.matmul(self.layer_list[i-1].activations, self.layer_list[i-1].weights), self.layer_list[i-1].bias)\n",
    "\n",
    "            if self.layer_list[i].activation_function == \"sigmoid\":\n",
    "                diff_a_z=sigmoid_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"relu\":\n",
    "                diff_a_z=relu_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"tanh\":\n",
    "                diff_a_z=tanh_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"linear\":\n",
    "                diff_a_z=derlinear(temp)\n",
    "\n",
    "            diff_z_w=self.layer_list[i-1].activations\n",
    "            diff_e_w=np.dot(diff_z_w.T,(diff_a_z*diff_e_a))\n",
    "            diff_e_b = diff_e_a*diff_a_z\n",
    "            diff_e_z=diff_e_b\n",
    "    \n",
    "            self.layer_list[i-1].weights -= self.learning_rate * diff_e_w\n",
    "            self.layer_list[i-1].bias -= self.learning_rate * diff_e_b.sum(axis=0)\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Network(inputs, num_epochs):\n",
    "    nn.error = 0\n",
    "    for j in range(num_epochs): \n",
    "        nn.forward_propagation(inputs)\n",
    "        nn.Error_func(inputs)\n",
    "        print(\"Iter \"+str(j)+\" : \"+str(nn.error))\n",
    "        nn.back_propagation(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn=Neu_net(layers=3, [l1,l2,l3], [None,\"f2\",\"f3\"])\n",
    "nn=Neu_net(5, [29,20,14,20,29], [None,\"sigmoid\",\"sigmoid\",\"sigmoid\",\"sigmoid\"])\n",
    "# nn=Neu_net(5, [29,21,14,21,29], [None,\"linear\",\"linear\",\"linear\",\"linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 : 0.624975566776099\n",
      "Iter 1 : 0.6025750057891243\n",
      "Iter 2 : 0.5841089719167772\n",
      "Iter 3 : 0.5690892231150022\n",
      "Iter 4 : 0.5570035713464623\n",
      "Iter 5 : 0.547348694503825\n",
      "Iter 6 : 0.5396597015978752\n",
      "Iter 7 : 0.5335315337977368\n",
      "Iter 8 : 0.5286278702097396\n",
      "Iter 9 : 0.5246792130946023\n",
      "Iter 10 : 0.5214746603541823\n",
      "Iter 11 : 0.5188514503498687\n",
      "Iter 12 : 0.516684798852953\n",
      "Iter 13 : 0.514879164000197\n",
      "Iter 14 : 0.5133612241212255\n",
      "Iter 15 : 0.5120744434928859\n",
      "Iter 16 : 0.5109749559094943\n",
      "Iter 17 : 0.51002848075727\n",
      "Iter 18 : 0.5092080228310016\n",
      "Iter 19 : 0.5084921569261491\n",
      "Iter 20 : 0.507863745087804\n",
      "Iter 21 : 0.5073089730431383\n",
      "Iter 22 : 0.5068166222664819\n",
      "Iter 23 : 0.5063775165243645\n",
      "Iter 24 : 0.5059840982083783\n",
      "Iter 25 : 0.5056301017470666\n",
      "Iter 26 : 0.5053103000782828\n",
      "Iter 27 : 0.5050203064635349\n",
      "Iter 28 : 0.5047564185025181\n",
      "Iter 29 : 0.5045154945426761\n",
      "Iter 30 : 0.5042948551225616\n",
      "Iter 31 : 0.5040922038873041\n",
      "Iter 32 : 0.5039055637471835\n",
      "Iter 33 : 0.5037332250431567\n",
      "Iter 34 : 0.5035737032273836\n",
      "Iter 35 : 0.5034257041280471\n",
      "Iter 36 : 0.5032880952936112\n",
      "Iter 37 : 0.50315988223674\n",
      "Iter 38 : 0.5030401886477162\n",
      "Iter 39 : 0.5029282398399735\n",
      "Iter 40 : 0.5028233488400853\n",
      "Iter 41 : 0.5027249046514778\n",
      "Iter 42 : 0.5026323623129366\n",
      "Iter 43 : 0.5025452344454124\n",
      "Iter 44 : 0.5024630840380834\n",
      "Iter 45 : 0.5023855182704274\n",
      "Iter 46 : 0.5023121832036981\n",
      "Iter 47 : 0.5022427592047012\n",
      "Iter 48 : 0.5021769569885678\n",
      "Iter 49 : 0.5021145141865534\n",
      "Iter 50 : 0.5020551923606217\n",
      "Iter 51 : 0.5019987743994432\n",
      "Iter 52 : 0.5019450622410021\n",
      "Iter 53 : 0.5018938748757092\n",
      "Iter 54 : 0.5018450465911131\n",
      "Iter 55 : 0.5017984254252733\n",
      "Iter 56 : 0.501753871800831\n",
      "Iter 57 : 0.5017112573159626\n",
      "Iter 58 : 0.5016704636718808\n",
      "Iter 59 : 0.5016313817194693\n",
      "Iter 60 : 0.5015939106101\n",
      "Iter 61 : 0.5015579570377653\n",
      "Iter 62 : 0.5015234345614268\n",
      "Iter 63 : 0.5014902629979648\n",
      "Iter 64 : 0.5014583678774148\n",
      "Iter 65 : 0.501427679953248\n",
      "Iter 66 : 0.5013981347614007\n",
      "Iter 67 : 0.5013696722225505\n",
      "Iter 68 : 0.5013422362828341\n",
      "Iter 69 : 0.5013157745887915\n",
      "Iter 70 : 0.5012902381928399\n",
      "Iter 71 : 0.5012655812860237\n",
      "Iter 72 : 0.5012417609551711\n",
      "Iter 73 : 0.5012187369619263\n",
      "Iter 74 : 0.5011964715414249\n",
      "Iter 75 : 0.5011749292186191\n",
      "Iter 76 : 0.5011540766405027\n",
      "Iter 77 : 0.501133882422665\n",
      "Iter 78 : 0.5011143170087872\n",
      "Iter 79 : 0.5010953525418329\n",
      "Iter 80 : 0.501076962745834\n",
      "Iter 81 : 0.5010591228172715\n",
      "Iter 82 : 0.5010418093251705\n",
      "Iter 83 : 0.5010250001191123\n",
      "Iter 84 : 0.5010086742444428\n",
      "Iter 85 : 0.5009928118640492\n",
      "Iter 86 : 0.5009773941861113\n",
      "Iter 87 : 0.5009624033973137\n",
      "Iter 88 : 0.5009478226010508\n",
      "Iter 89 : 0.5009336357601928\n",
      "Iter 90 : 0.5009198276440341\n",
      "Iter 91 : 0.5009063837790716\n",
      "Iter 92 : 0.5008932904033027\n",
      "Iter 93 : 0.5008805344237449\n",
      "Iter 94 : 0.5008681033769353\n",
      "Iter 95 : 0.5008559853921525\n",
      "Iter 96 : 0.5008441691571599\n",
      "Iter 97 : 0.5008326438862665\n",
      "Iter 98 : 0.500821399290531\n",
      "Iter 99 : 0.500810425549938\n"
     ]
    }
   ],
   "source": [
    "Training_Network(df.values,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight & Bias: Saving and Retrieving by file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nn.layers):\n",
    "    np.save('wgts'+str(i)+'.npy',nn.layer_list[i].weights)\n",
    "    np.save('bias'+str(i)+'.npy',nn.layer_list[i].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nn.layers):\n",
    "    nn.layer_list[i].weights = np.load('wgts'+str(i)+'.npy')\n",
    "    nn.layer_list[i].bias=np.load('bias'+str(i)+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data-Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.forward_propagation(validate.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=nn.layer_list[2].activations\n",
    "dimensions=ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24998, 14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58250553, 0.58133921, 0.58014624, ..., 0.58150141, 0.58177027,\n",
       "        0.57995285],\n",
       "       [0.57939388, 0.57828203, 0.57713478, ..., 0.57845524, 0.57869517,\n",
       "        0.57694961],\n",
       "       [0.58250976, 0.58134319, 0.58015017, ..., 0.58150537, 0.58177406,\n",
       "        0.5799566 ],\n",
       "       ...,\n",
       "       [0.57735929, 0.57627617, 0.57515737, ..., 0.57645517, 0.57668783,\n",
       "        0.57499144],\n",
       "       [0.58204005, 0.58088436, 0.57969746, ..., 0.58104602, 0.58131378,\n",
       "        0.57950668],\n",
       "       [0.58080675, 0.57966901, 0.57850112, ..., 0.57983215, 0.58008714,\n",
       "        0.57831051]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(k,dimensions) :\n",
    "    rows = dimensions.shape[0]\n",
    "    cols = dimensions.shape[1]\n",
    "    \n",
    "    mn = np.mean(dimensions, axis = 0)\n",
    "    #print(mn)\n",
    "    std = np.std(dimensions, axis = 0)\n",
    "    #print(std)\n",
    "    centers = np.random.randn(k,cols)*std + mn\n",
    "    #print(centers)\n",
    "#     plt.scatter(centers[:,0], centers[:,1], marker='+', c='r', s=150)\n",
    "    \n",
    "    # to store old centers\n",
    "    co = np.zeros(centers.shape)\n",
    "    # to Store new centers\n",
    "    cn = deepcopy(centers) \n",
    "\n",
    "    clusters = np.zeros(rows)\n",
    "    distances = np.zeros((rows,k))\n",
    "\n",
    "    error = np.linalg.norm(cn - co)\n",
    "\n",
    "    # When, after an update, the estimate of that center stays the same, exit loop\n",
    "    while error != 0:\n",
    "        # Measure the distance to every center\n",
    "        for i in range(k):\n",
    "            distances[:,i] = np.linalg.norm(dimensions - cn[i], axis=1)\n",
    "        # Assign all training data to closest center\n",
    "        clusters = np.argmin(distances, axis = 1)\n",
    "\n",
    "        co = deepcopy(cn)\n",
    "        # Calculate mean for every cluster and update the center\n",
    "        for i in range(k):\n",
    "            cn[i] = np.mean(dimensions[clusters == i], axis=0)\n",
    "        error = np.linalg.norm(cn - co)\n",
    "    # centers_new   \n",
    "#     plt.scatter(cn[:,0], cn[:,1], marker='+', c='g', s=150)\n",
    "#     print(clusters)\n",
    "#     print(np.unique(clusters))\n",
    "    \n",
    "    #\n",
    "    cmat=contingency_matrix(clusters,lclass)\n",
    "#     print(cmat)\n",
    "\n",
    "    for i,item in enumerate(cmat):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "    \n",
    "    pure=0\n",
    "    for row in cmat:\n",
    "#         print(max(row))\n",
    "        pure+=max(row)\n",
    "    purity0=pure/len(df_label)\n",
    "    \n",
    "    return purity0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_fun(dimensions) :\n",
    "    \n",
    "    GMM=GaussianMixture(n_components=5).fit(dimensions)\n",
    "    gmmlabel=GMM.predict(dimensions)\n",
    "    \n",
    "    np.unique(gmmlabel)\n",
    "    cmat=contingency_matrix(gmmlabel,lclass)\n",
    "\n",
    "    for i,item in enumerate(cmat):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "\n",
    "    pure1=0\n",
    "    for i in cmat:\n",
    "        pure1+=max(i)\n",
    "    #     print(max(i))\n",
    "    purity1=pure1/len(df_label)\n",
    "    print('GMM Purity:', purity1)\n",
    "    \n",
    "    return purity1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierrarchial Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchial_cluster(dimensions) :\n",
    "    cc=AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='single')\n",
    "    aclabel=cc.fit_predict(dimensions)\n",
    "    np.unique(aclabel)\n",
    "    \n",
    "    cmat2=contingency_matrix(aclabel,lclass)\n",
    "    \n",
    "    for i,item in enumerate(cmat2):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "\n",
    "    pure2=0\n",
    "    for i in cmat2:\n",
    "        pure2+=max(i)\n",
    "    purity2=pure2/len(df_label)\n",
    "    print('Hierarchical Purity:', purity2)\n",
    "    \n",
    "    return purity2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting unique vals of label [xAttack] attr into integer categories\n",
    "uv = np.unique(df_label)\n",
    "# print(uv)\n",
    "cat = [0,1,2,3,4]\n",
    "#converted label data into int class list \n",
    "lclass=[]\n",
    "for i in range(len(df_label)):\n",
    "    if df_label[i]=='dos':\n",
    "        lclass.append(cat[0])\n",
    "    if df_label[i]=='normal':\n",
    "        lclass.append(cat[1])\n",
    "    if df_label[i]=='probe':\n",
    "        lclass.append(cat[2])\n",
    "    if df_label[i]=='r2l':\n",
    "        lclass.append(cat[3])\n",
    "    if df_label[i]=='u2r':\n",
    "        lclass.append(cat[4])\n",
    "# print(lclass)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of clusters : 0  : 69.2702760539268\n",
      "Purity of clusters : 1  : 93.62875013251352\n",
      "Purity of clusters : 2  : 70.09249743062692\n",
      "Purity of clusters : 3  : 81.44011406844106\n",
      "Purity of clusters : 4  : 95.84905660377359\n",
      "K-means Purity is: 0.8318665493239459\n"
     ]
    }
   ],
   "source": [
    "# kmeans on reduced dimenasions\n",
    "k = 5\n",
    "purity0 = k_means(k,dimensions)\n",
    "print('K-means Purity is:', purity0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of clusters : 0  : 78.90782686701054\n",
      "Purity of clusters : 1  : 86.62312885236278\n",
      "Purity of clusters : 2  : 55.947497949138636\n",
      "Purity of clusters : 3  : 92.85714285714286\n",
      "GMM Purity: 0.8088247059764782\n"
     ]
    }
   ],
   "source": [
    "#GMM_fun\n",
    "purity1 = GMM_fun(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of clusters : 0  : 100.0\n",
      "Purity of clusters : 1  : 50.0\n",
      "Purity of clusters : 2  : 100.0\n",
      "Purity of clusters : 3  : 100.0\n",
      "Purity of clusters : 4  : 53.44751690743927\n",
      "Hierarchical Purity: 0.5346027682214577\n"
     ]
    }
   ],
   "source": [
    "#Hierarchial clustering\n",
    "purity2 = hierarchial_cluster(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIE Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "slices_hours = [purity0, purity1, purity2]\n",
    "activities = ['K-Means', 'GMM', 'Hierarchical']\n",
    "explode = (0.025, 0.025, 0.025)\n",
    "colors = ['red', 'blue','green']\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(slices_hours, explode=explode,colors=colors, labels=activities, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=120)\n",
    "ax1.axis('equal') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
