{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "from numpy import linalg as la\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>193</td>\n",
       "      <td>441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>167</td>\n",
       "      <td>9724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  service  src_bytes  dst_bytes  hot  num_failed_logins  \\\n",
       "0         0       25        193        441    0                  0   \n",
       "1         0       38          0          0    0                  0   \n",
       "2         0       25        167       9724    0                  0   \n",
       "3         0       20       1339          0    0                  0   \n",
       "4         0       37          0          0    0                  0   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "0                0         0                   0                 0  ...   \n",
       "1                0         0                   0                 0  ...   \n",
       "2                0         0                   0                 0  ...   \n",
       "3                0         0                   0                 0  ...   \n",
       "4                0         0                   0                 0  ...   \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                 255                    1.00                    0.00   \n",
       "1                   1                    0.00                    0.07   \n",
       "2                 255                    1.00                    0.00   \n",
       "3                  31                    0.23                    0.04   \n",
       "4                  25                    0.10                    0.05   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.07                         0.04   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.03                         0.06   \n",
       "3                         0.23                         0.00   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.04                   0.0   \n",
       "1                  0.00                      0.00                   1.0   \n",
       "2                  0.00                      0.00                   0.0   \n",
       "3                  0.02                      0.00                   0.0   \n",
       "4                  1.00                      1.00                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                       0.0   normal  \n",
       "1                       1.0      dos  \n",
       "2                       0.0   normal  \n",
       "3                       0.0   normal  \n",
       "4                       0.0      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df[0:2000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24998, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df_label=df.iloc[:,-1]\n",
    "df.drop(df.columns[[-1,]], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df['dst'])\n",
    "# df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dos' 'normal' 'probe' 'r2l' 'u2r']\n",
      "[ 9114 13364  2313   197    10]\n"
     ]
    }
   ],
   "source": [
    "x,y= np.unique(df_label,return_counts =True)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration                         310.648452\n",
      "service                           32.024842\n",
      "src_bytes                      24424.087767\n",
      "dst_bytes                       3305.596648\n",
      "hot                                0.193535\n",
      "num_failed_logins                  0.001200\n",
      "num_compromised                    0.229418\n",
      "num_root                           0.251700\n",
      "num_file_creations                 0.014841\n",
      "num_access_files                   0.004360\n",
      "count                             84.466757\n",
      "srv_count                         27.767061\n",
      "serror_rate                        0.284812\n",
      "srv_serror_rate                    0.282262\n",
      "rerror_rate                        0.119152\n",
      "srv_rerror_rate                    0.120744\n",
      "same_srv_rate                      0.661691\n",
      "diff_srv_rate                      0.062590\n",
      "srv_diff_host_rate                 0.096546\n",
      "dst_host_count                   182.405832\n",
      "dst_host_srv_count               115.254580\n",
      "dst_host_same_srv_rate             0.520648\n",
      "dst_host_diff_srv_rate             0.083117\n",
      "dst_host_same_src_port_rate        0.148392\n",
      "dst_host_srv_diff_host_rate        0.032109\n",
      "dst_host_serror_rate               0.284272\n",
      "dst_host_srv_serror_rate           0.278418\n",
      "dst_host_rerror_rate               0.118272\n",
      "dst_host_srv_rerror_rate           0.119189\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.690213</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.447897</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488729</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  ...  \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087  ...   \n",
       "\n",
       "   dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0       -1.690213            1.262872                1.067572   \n",
       "1        0.732947           -1.032512               -1.159545   \n",
       "2       -1.447897            1.262872                1.067572   \n",
       "3       -0.488729           -0.761404               -0.647308   \n",
       "4        0.732947           -0.815626               -0.936833   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0               -0.441083                    -0.253425   \n",
       "1               -0.069609                    -0.479722   \n",
       "2               -0.441083                    -0.382738   \n",
       "3               -0.228812                     0.263823   \n",
       "4               -0.175745                    -0.479722   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                     0.071030             -0.639500   \n",
       "1                    -0.289006             -0.639500   \n",
       "2                     0.251048             -0.639500   \n",
       "3                    -0.289006             -0.594507   \n",
       "4                    -0.289006              1.610108   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \n",
       "0                 -0.535332             -0.386077                 -0.374982  \n",
       "1                 -0.625146              2.878240                  2.771138  \n",
       "2                 -0.625146             -0.386077                 -0.374982  \n",
       "3                 -0.625146             -0.386077                 -0.374982  \n",
       "4                  1.620205             -0.386077                 -0.374982  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=np.mean(df)\n",
    "print(mean)\n",
    "std_dev=np.std(df)\n",
    "df=(df-np.mean(df,axis=0))/np.std(df,axis=0)\n",
    "# df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to put Weight and Bias between Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wgt_n_Bias:\n",
    "    def __init__(self, current_layer_nodes,next_layer_nodes, activation_function):\n",
    "        #nodes in current layer\n",
    "        self.current_layer_nodes = current_layer_nodes\n",
    "        #nodes in next layer\n",
    "        self.next_layer_nodes = next_layer_nodes\n",
    "        #activation_function \n",
    "        self.activation_function = activation_function\n",
    "        #activations\n",
    "        self.activations = np.zeros([current_layer_nodes,1])\n",
    "        \n",
    "        # putting weights and bias for layers\n",
    "        \n",
    "        # if not output layer set random weights and bias\n",
    "        if next_layer_nodes != 0:\n",
    "            self.weights = np.random.normal(0, 0.001, size=(current_layer_nodes, next_layer_nodes))\n",
    "            self.bias = np.random.normal(0, 0.001, size=(1, next_layer_nodes))\n",
    "        # if output layer set weight and bias to None\n",
    "        else:\n",
    "            self.weights = None\n",
    "            self.bias = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):  \n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):  \n",
    "    return sigmoid(x) *(1-sigmoid (x))\n",
    "\n",
    "def softmax(A):  \n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    x[x < 0] = 0\n",
    "    return x\n",
    "\n",
    "def tanh_der(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "def relu_der(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def derlinear(x):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to  make Neural Nertwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neu_net:\n",
    "    def __init__(self, layers, node_list, activation_function):\n",
    "        self.layers = layers\n",
    "        self.node_list = node_list\n",
    "        self.layer_list = []\n",
    "        self.error = 0\n",
    "        self.learning_rate = 0.0001\n",
    "        self.cost_function = \"mean_squared\"\n",
    "\n",
    "        for i in range(layers):\n",
    "            \n",
    "            if i != layers-1:\n",
    "                layer_i = Wgt_n_Bias(node_list[i], node_list[i+1], activation_function[i])\n",
    "            else:\n",
    "                #if i is output layer\n",
    "                layer_i = Wgt_n_Bias(node_list[i], 0, activation_function[i])\n",
    "            self.layer_list.append(layer_i)\n",
    "                   \n",
    "\n",
    "    def forward_propagation(self, inputs):\n",
    "        self.layer_list[0].activations = inputs\n",
    "        for i in range(self.layers-1):\n",
    "            \n",
    "            temp = np.add(np.matmul(self.layer_list[i].activations, self.layer_list[i].weights), self.layer_list[i].bias)\n",
    "\n",
    "            if self.layer_list[i+1].activation_function == \"sigmoid\":\n",
    "                self.layer_list[i+1].activations = sigmoid(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"softmax\":\n",
    "                self.layer_list[i+1].activations = softmax(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"relu\":\n",
    "                self.layer_list[i+1].activations = relu(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"tanh\":\n",
    "                self.layer_list[i+1].activations = tanh(temp)\n",
    "            elif self.layer_list[i+1].activation_function == \"linear\":\n",
    "                self.layer_list[i+1].activations = linear(temp)\n",
    "            else:\n",
    "                self.layer_list[i+1].activations = temp\n",
    "    \n",
    "    #Error func - mean-squared\n",
    "    def Error_func(self,label_vector):\n",
    "            #self.error = np.sum(-label_vector * np.log(self.layer_list[-1].activations))\n",
    "        self.error = np.mean(np.divide(np.square(np.subtract(label_vector, self.layer_list[self.layers-1].activations)), 2))\n",
    "    \n",
    "    def back_propagation(self,label_vector):\n",
    "        \n",
    "        #for the weight and bias of output layer\n",
    "        i = self.layers-1\n",
    "        diff_a_z=0\n",
    "        \n",
    "        #\n",
    "        if self.layer_list[i].activation_function == \"sigmoid\":\n",
    "            diff_e_z=self.layer_list[i].activations*(1-self.layer_list[i].activations)*(self.layer_list[i].activations-label_vector)\n",
    "        else:\n",
    "            diff_e_z=self.layer_list[i].activations-label_vector\n",
    "        #diff_e_z=self.layer_list[i].activations-label_vector\n",
    "        diff_z_w=self.layer_list[i-1].activations\n",
    "        diff_e_w=np.dot(diff_z_w.T, diff_e_z) \n",
    "        diff_e_b=diff_e_z\n",
    "\n",
    "        self.layer_list[i-1].weights -= self.learning_rate * diff_e_w\n",
    "        self.layer_list[i-1].bias -= self.learning_rate * diff_e_b.sum(axis=0)\n",
    "       \n",
    "        for i in range(i-1,0,-1):\n",
    "            diff_z_a=self.layer_list[i].weights\n",
    "            diff_e_a=np.dot(diff_e_z,diff_z_a.T)\n",
    "            \n",
    "            temp = np.add(np.matmul(self.layer_list[i-1].activations, self.layer_list[i-1].weights), self.layer_list[i-1].bias)\n",
    "\n",
    "            if self.layer_list[i].activation_function == \"sigmoid\":\n",
    "                diff_a_z=sigmoid_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"relu\":\n",
    "                diff_a_z=relu_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"tanh\":\n",
    "                diff_a_z=tanh_der(temp)\n",
    "            if self.layer_list[i].activation_function == \"linear\":\n",
    "                diff_a_z=derlinear(temp)\n",
    "\n",
    "            diff_z_w=self.layer_list[i-1].activations\n",
    "            diff_e_w=np.dot(diff_z_w.T,(diff_a_z*diff_e_a))\n",
    "            diff_e_b = diff_e_a*diff_a_z\n",
    "            diff_e_z=diff_e_b\n",
    "    \n",
    "            self.layer_list[i-1].weights -= self.learning_rate * diff_e_w\n",
    "            self.layer_list[i-1].bias -= self.learning_rate * diff_e_b.sum(axis=0)\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Network(inputs, num_epochs):\n",
    "    nn.error = 0\n",
    "    for j in range(num_epochs): \n",
    "        nn.forward_propagation(inputs)\n",
    "        nn.Error_func(inputs)\n",
    "        print(\"Iter \"+str(j)+\" : \"+str(nn.error))\n",
    "        nn.back_propagation(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn=Neu_net(layers=3, [l1,l2,l3], [None,\"f2\",\"f3\"])\n",
    "nn=Neu_net(3, [29,14,29], [None,\"sigmoid\",\"sigmoid\"])\n",
    "# nn=Neu_net(5, [29,21,14,21,29], [None,\"linear\",\"linear\",\"linear\",\"linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 : 0.6249493678410067\n",
      "Iter 1 : 0.5086131778104498\n",
      "Iter 2 : 0.4997648702153988\n",
      "Iter 3 : 0.49619089245498477\n",
      "Iter 4 : 0.4937527270046982\n",
      "Iter 5 : 0.49169949912308536\n",
      "Iter 6 : 0.4897927379207087\n",
      "Iter 7 : 0.48794632251042297\n",
      "Iter 8 : 0.48613492489158094\n",
      "Iter 9 : 0.48435989811022495\n",
      "Iter 10 : 0.48263128046985815\n",
      "Iter 11 : 0.4809553606055476\n",
      "Iter 12 : 0.4793242065571895\n",
      "Iter 13 : 0.4777043399425359\n",
      "Iter 14 : 0.4760203554671776\n",
      "Iter 15 : 0.47412668279349957\n",
      "Iter 16 : 0.47175594199592547\n",
      "Iter 17 : 0.46843093091977933\n",
      "Iter 18 : 0.46341550945407367\n",
      "Iter 19 : 0.4562950614160412\n",
      "Iter 20 : 0.44863790630093975\n",
      "Iter 21 : 0.44261278310643004\n",
      "Iter 22 : 0.43830948866235386\n",
      "Iter 23 : 0.4351309012016586\n",
      "Iter 24 : 0.43264115248063406\n",
      "Iter 25 : 0.4305517919098725\n",
      "Iter 26 : 0.42864733795172205\n",
      "Iter 27 : 0.4268846967954651\n",
      "Iter 28 : 0.42541031694396986\n",
      "Iter 29 : 0.42416607133852774\n",
      "Iter 30 : 0.42307953123342157\n",
      "Iter 31 : 0.4221122676538864\n",
      "Iter 32 : 0.4212346651972599\n",
      "Iter 33 : 0.42042210379485956\n",
      "Iter 34 : 0.41965306100978844\n",
      "Iter 35 : 0.41890802242309905\n",
      "Iter 36 : 0.41817028934904615\n",
      "Iter 37 : 0.4174311081854888\n",
      "Iter 38 : 0.41669850184121576\n",
      "Iter 39 : 0.4159914861306469\n",
      "Iter 40 : 0.4153076704558594\n",
      "Iter 41 : 0.4146230714333791\n",
      "Iter 42 : 0.41392181802632083\n",
      "Iter 43 : 0.41319678295545725\n",
      "Iter 44 : 0.4124483717651356\n",
      "Iter 45 : 0.4116916137865719\n",
      "Iter 46 : 0.41095578483115264\n",
      "Iter 47 : 0.4102623973704774\n",
      "Iter 48 : 0.4096100149031986\n",
      "Iter 49 : 0.4089909435542912\n",
      "Iter 50 : 0.4084020685582464\n",
      "Iter 51 : 0.4078418595997725\n",
      "Iter 52 : 0.4073082088503814\n",
      "Iter 53 : 0.4067981657211464\n",
      "Iter 54 : 0.4063080321360553\n",
      "Iter 55 : 0.4058334179359769\n",
      "Iter 56 : 0.4053692078416268\n",
      "Iter 57 : 0.404909493581386\n",
      "Iter 58 : 0.40444766831503215\n",
      "Iter 59 : 0.4039771910493372\n",
      "Iter 60 : 0.4034939949033991\n",
      "Iter 61 : 0.4030013122767024\n",
      "Iter 62 : 0.40251420366468843\n",
      "Iter 63 : 0.4020544498058946\n",
      "Iter 64 : 0.4016329007351879\n",
      "Iter 65 : 0.40124139775170276\n",
      "Iter 66 : 0.40086617818802256\n",
      "Iter 67 : 0.400499053436721\n",
      "Iter 68 : 0.4001366332046319\n",
      "Iter 69 : 0.39977728396524753\n",
      "Iter 70 : 0.39941984402043523\n",
      "Iter 71 : 0.39906333295630925\n",
      "Iter 72 : 0.3987069569522848\n",
      "Iter 73 : 0.3983502020863285\n",
      "Iter 74 : 0.39799295402109025\n",
      "Iter 75 : 0.39763558450033765\n",
      "Iter 76 : 0.3972789190827966\n",
      "Iter 77 : 0.39692401583403386\n",
      "Iter 78 : 0.3965717906084146\n",
      "Iter 79 : 0.39622267535361244\n",
      "Iter 80 : 0.3958765240059065\n",
      "Iter 81 : 0.3955327945800375\n",
      "Iter 82 : 0.3951908211364535\n",
      "Iter 83 : 0.39484998305907315\n",
      "Iter 84 : 0.39450973147491436\n",
      "Iter 85 : 0.39416953967715634\n",
      "Iter 86 : 0.3938288455983828\n",
      "Iter 87 : 0.39348701784383666\n",
      "Iter 88 : 0.39314335565186614\n",
      "Iter 89 : 0.3927971321547075\n",
      "Iter 90 : 0.39244769557769443\n",
      "Iter 91 : 0.3920946373578187\n",
      "Iter 92 : 0.39173800141807386\n",
      "Iter 93 : 0.39137844407597777\n",
      "Iter 94 : 0.391017214101161\n",
      "Iter 95 : 0.39065589917568355\n",
      "Iter 96 : 0.39029605874273277\n",
      "Iter 97 : 0.3899389447710464\n",
      "Iter 98 : 0.3895854063371149\n",
      "Iter 99 : 0.3892359316537608\n"
     ]
    }
   ],
   "source": [
    "Training_Network(df.values,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight & Bias: Saving and Retrieving by file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nn.layers):\n",
    "    np.save('wgts'+str(i)+'.npy',nn.layer_list[i].weights)\n",
    "    np.save('bias'+str(i)+'.npy',nn.layer_list[i].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nn.layers):\n",
    "    nn.layer_list[i].weights = np.load('wgts'+str(i)+'.npy')\n",
    "    nn.layer_list[i].bias=np.load('bias'+str(i)+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data-Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.forward_propagation(validate.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=nn.layer_list[1].activations\n",
    "dimensions=ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24998, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.19850289e-01, 9.72411609e-01, 6.63479304e-01, ...,\n",
       "        9.82882515e-01, 9.77682910e-01, 8.31728293e-01],\n",
       "       [1.75686292e-02, 8.23941508e-04, 1.78153796e-02, ...,\n",
       "        9.69569432e-01, 5.55978553e-04, 1.10977051e-02],\n",
       "       [7.13117652e-01, 9.69223411e-01, 7.43352854e-01, ...,\n",
       "        9.86308875e-01, 9.71798384e-01, 8.61312149e-01],\n",
       "       ...,\n",
       "       [3.45697014e-03, 5.25111868e-03, 3.30886161e-03, ...,\n",
       "        2.43494813e-03, 2.33586829e-04, 4.13953284e-03],\n",
       "       [2.09497351e-03, 9.95492751e-01, 1.75953042e-03, ...,\n",
       "        9.89997751e-01, 9.98363801e-01, 3.37972777e-03],\n",
       "       [9.94616708e-01, 9.53529858e-02, 9.93441536e-01, ...,\n",
       "        9.67026346e-03, 2.03125755e-01, 9.83099729e-01]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(k,dimensions) :\n",
    "    rows = dimensions.shape[0]\n",
    "    cols = dimensions.shape[1]\n",
    "    \n",
    "    mn = np.mean(dimensions, axis = 0)\n",
    "    #print(mn)\n",
    "    std = np.std(dimensions, axis = 0)\n",
    "    #print(std)\n",
    "    centers = np.random.randn(k,cols)*std + mn\n",
    "    #print(centers)\n",
    "#     plt.scatter(centers[:,0], centers[:,1], marker='+', c='r', s=150)\n",
    "    \n",
    "    # to store old centers\n",
    "    co = np.zeros(centers.shape)\n",
    "    # to Store new centers\n",
    "    cn = deepcopy(centers) \n",
    "\n",
    "    clusters = np.zeros(rows)\n",
    "    distances = np.zeros((rows,k))\n",
    "\n",
    "    error = np.linalg.norm(cn - co)\n",
    "\n",
    "    # When, after an update, the estimate of that center stays the same, exit loop\n",
    "    while error != 0:\n",
    "        # Measure the distance to every center\n",
    "        for i in range(k):\n",
    "            distances[:,i] = np.linalg.norm(dimensions - cn[i], axis=1)\n",
    "        # Assign all training data to closest center\n",
    "        clusters = np.argmin(distances, axis = 1)\n",
    "\n",
    "        co = deepcopy(cn)\n",
    "        # Calculate mean for every cluster and update the center\n",
    "        for i in range(k):\n",
    "            cn[i] = np.mean(dimensions[clusters == i], axis=0)\n",
    "        error = np.linalg.norm(cn - co)\n",
    "    # centers_new   \n",
    "#     plt.scatter(cn[:,0], cn[:,1], marker='+', c='g', s=150)\n",
    "#     print(clusters)\n",
    "#     print(np.unique(clusters))\n",
    "    \n",
    "    #\n",
    "    cmat=contingency_matrix(clusters,lclass)\n",
    "#     print(cmat)\n",
    "\n",
    "    for i,item in enumerate(cmat):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "    \n",
    "    pure=0\n",
    "    for row in cmat:\n",
    "#         print(max(row))\n",
    "        pure+=max(row)\n",
    "    purity0=pure/len(df_label)\n",
    "    \n",
    "    return purity0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_fun(dimensions) :\n",
    "    \n",
    "    GMM=GaussianMixture(n_components=5).fit(dimensions)\n",
    "    gmmlabel=GMM.predict(dimensions)\n",
    "    \n",
    "    np.unique(gmmlabel)\n",
    "    cmat=contingency_matrix(gmmlabel,lclass)\n",
    "\n",
    "    for i,item in enumerate(cmat):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "\n",
    "    pure1=0\n",
    "    for i in cmat:\n",
    "        pure1+=max(i)\n",
    "    #     print(max(i))\n",
    "    purity1=pure1/len(df_label)\n",
    "    print('GMM Purity:', purity1)\n",
    "    \n",
    "    return purity1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierrarchial Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchial_cluster(dimensions) :\n",
    "    cc=AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='single')\n",
    "    aclabel=cc.fit_predict(dimensions)\n",
    "    np.unique(aclabel)\n",
    "    \n",
    "    cmat2=contingency_matrix(aclabel,lclass)\n",
    "    \n",
    "    for i,item in enumerate(cmat2):\n",
    "        print(\"Purity of clusters :\",i,\" :\", max(item)*100/sum(item))\n",
    "\n",
    "    pure2=0\n",
    "    for i in cmat2:\n",
    "        pure2+=max(i)\n",
    "    purity2=pure2/len(df_label)\n",
    "    print('Hierarchical Purity:', purity2)\n",
    "    \n",
    "    return purity2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting unique vals of label [xAttack] attr into integer categories\n",
    "uv = np.unique(df_label)\n",
    "# print(uv)\n",
    "cat = [0,1,2,3,4]\n",
    "#converted label data into int class list \n",
    "lclass=[]\n",
    "for i in range(len(df_label)):\n",
    "    if df_label[i]=='dos':\n",
    "        lclass.append(cat[0])\n",
    "    if df_label[i]=='normal':\n",
    "        lclass.append(cat[1])\n",
    "    if df_label[i]=='probe':\n",
    "        lclass.append(cat[2])\n",
    "    if df_label[i]=='r2l':\n",
    "        lclass.append(cat[3])\n",
    "    if df_label[i]=='u2r':\n",
    "        lclass.append(cat[4])\n",
    "# print(lclass)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of clusters : 0  : 98.38009835117154\n",
      "Purity of clusters : 1  : 69.66993755575379\n",
      "Purity of clusters : 2  : 96.1617482256257\n",
      "Purity of clusters : 3  : 44.657356284507955\n",
      "Purity of clusters : 4  : 51.13350125944584\n",
      "K-means Purity is: 0.8352268181454516\n"
     ]
    }
   ],
   "source": [
    "# kmeans on reduced dimenasions\n",
    "k = 5\n",
    "purity0 = k_means(k,dimensions)\n",
    "print('K-means Purity is:', purity0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of clusters : 0  : 99.0132468234658\n",
      "Purity of clusters : 1  : 48.8713722680043\n",
      "Purity of clusters : 2  : 100.0\n",
      "Purity of clusters : 3  : 76.34864546525324\n",
      "Purity of clusters : 4  : 58.31496448689689\n",
      "GMM Purity: 0.8317465397231778\n"
     ]
    }
   ],
   "source": [
    "#GMM_fun\n",
    "purity1 = GMM_fun(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of clusters : 0  : 53.44910371318822\n",
      "Purity of clusters : 1  : 100.0\n",
      "Purity of clusters : 2  : 100.0\n",
      "Purity of clusters : 3  : 100.0\n",
      "Purity of clusters : 4  : 100.0\n",
      "Hierarchical Purity: 0.5346027682214577\n"
     ]
    }
   ],
   "source": [
    "#Hierarchial clustering\n",
    "purity2 = hierarchial_cluster(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIE Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "slices_hours = [purity0, purity1, purity2]\n",
    "activities = ['K-Means', 'GMM', 'Hierarchical']\n",
    "explode = (0.025, 0.025, 0.025)\n",
    "colors = ['red', 'blue','green']\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(slices_hours, explode=explode,colors=colors, labels=activities, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=120)\n",
    "ax1.axis('equal') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
